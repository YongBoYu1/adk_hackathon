from google.adk.agents import LlmAgent
from google.adk.runners import BaseAgent, InvocationContext
from google.adk.events import Event
from google.adk.tools import FunctionTool
from google.adk.tools.tool_context import ToolContext
from .tool import AUDIO_TOOLS, audio_processor
import asyncio
from typing import Dict, Any, Optional, AsyncGenerator
from datetime import datetime


class AudioAgent(BaseAgent):
    """
    NHL Commentary Audio Agent - Responsible for converting commentary text to speech and streaming audio
    
    Audio processing agent built on Google ADK, specifically designed for:
    1. Receiving commentary text generated by commentary agent
    2. Converting to high-quality speech using Google Cloud TTS
    3. Real-time streaming audio via WebSocket
    4. Supporting multiple voice styles and languages
    """
    
    def __init__(self, name: str = "nhl_audio_agent", model: str = "gemini-2.0-flash", **kwargs):
        # Call parent constructor
        super().__init__(name=name, **kwargs)
        
        # Store custom attributes in private variables
        self._model = model
        self._websocket_server_running = False
        self._websocket_server_task = None
        
        # Create internal LLM agent for text processing
        self._llm_agent = self._create_llm_agent()
        
    @property
    def model(self) -> str:
        """Get model name"""
        return self._model
    
    @property 
    def websocket_server_running(self) -> bool:
        """Get WebSocket server running status"""
        return self._websocket_server_running
        
    @websocket_server_running.setter
    def websocket_server_running(self, value: bool):
        """Set WebSocket server running status"""
        self._websocket_server_running = value
        
    @property
    def llm_agent(self):
        """Get internal LLM agent"""
        return self._llm_agent
        
    def _create_llm_agent(self) -> LlmAgent:
        """Create ADK LLM agent instance"""
        
        agent_instruction = """
You are a professional audio agent for NHL hockey games, responsible for converting commentary text into high-quality speech output.

## Core Responsibilities:
1. **Text-to-Speech**: Use text_to_speech tool to convert commentary text to speech
2. **Audio Stream Management**: Use stream_audio_websocket tool to start WebSocket server
3. **Status Monitoring**: Use get_audio_status tool to monitor audio system status

## Tool Usage Guidelines:

### text_to_speech Tool
- Used to convert commentary text generated by commentary agent into speech
- Supports multiple voice styles: enthusiastic, dramatic, calm
- Choose appropriate voice style based on commentary content:
  - Goals, great saves → enthusiastic
  - Penalties, key moments → dramatic  
  - General game commentary → enthusiastic (default)
- Automatically handles SSML markup to enhance speech expressiveness

### stream_audio_websocket Tool
- Automatically starts WebSocket server when receiving first audio generation request
- Default port 8765, customizable
- Real-time broadcast audio data to all connected clients

### get_audio_status Tool
- Used to monitor audio system status
- Shows connected client count, audio queue status, history, etc.
- Used for diagnostics when issues occur

## Processing Flow:
1. Receive commentary text input
2. Analyze text content, choose appropriate voice style
3. Use text_to_speech to convert to audio
4. Ensure WebSocket server is running
5. Automatically broadcast audio to all connected clients
6. Return processing status and audio ID

## Error Handling:
- If TTS fails, return detailed error message and suggest retry
- If WebSocket server startup fails, try using backup port
- Monitor client connection status, automatically clean up disconnected connections

## Speech Quality Optimization:
- Optimize speech rate for hockey commentary (1.1x-1.2x)
- Use male voice suitable for sports commentary
- Dynamically adjust pitch and volume based on commentary content
- Support SSML for enhanced expressiveness

Remember: Your goal is to provide high-quality, real-time voice commentary service for NHL games, making listeners feel the passion and tension of the game.
"""

        return LlmAgent(
            name="nhl_audio_llm_agent",
            model=self.model,
            instruction=agent_instruction,
            description="NHL Hockey Game Audio Agent - Professional text-to-speech and audio streaming service",
            tools=AUDIO_TOOLS
        )
    
    async def _run_async_impl(self, ctx: InvocationContext) -> AsyncGenerator[Event, None]:
        """
        Implement core logic of custom audio agent
        
        This method defines the execution flow of the audio agent:
        1. Check input text
        2. Intelligently select voice style
        3. Start WebSocket server (if needed)
        4. Generate audio and stream
        5. Return processing results
        """
        try:
            print(f"🎯 [{self.name}] Starting audio processing workflow...")
            
            # Get input text from session state
            input_text = ctx.session.state.get("commentary_text") or ctx.session.state.get("text")
            
            if not input_text:
                # If no text found, try to get from last user message
                if hasattr(ctx, 'user_message') and ctx.user_message:
                    input_text = str(ctx.user_message)
                else:
                    # Create error event
                    error_event = Event(
                        id="audio_error",
                        type="error",
                        content="No text content found for audio conversion",
                        author=self.name
                    )
                    yield error_event
                    return
            
            print(f"🎙️ [{self.name}] Processing text: {input_text[:50]}...")
            
            # Intelligently analyze voice style
            voice_style = self._analyze_voice_style(input_text)
            
            # Set processing parameters to session state
            ctx.session.state["current_text"] = input_text
            ctx.session.state["voice_style"] = voice_style
            ctx.session.state["audio_processing_status"] = "started"
            
            # Step 1: Ensure WebSocket server is running
            if not self.websocket_server_running:
                yield Event(
                    id="websocket_start",
                    type="info", 
                    content="Starting WebSocket audio streaming server...",
                    author=self.name
                )
                
                # Call tools through LLM agent
                async for event in self.llm_agent.run_async(ctx):
                    # Check tool call events
                    if hasattr(event, 'tool_call') and event.tool_call:
                        if event.tool_call.function.name == "stream_audio_websocket":
                            self.websocket_server_running = True
                    yield event
            
            # Step 2: Generate audio
            yield Event(
                id="audio_generation",
                type="info",
                content=f"Generating audio with {voice_style} style...",
                author=self.name
            )
            
            # Let LLM agent handle audio generation
            async for event in self.llm_agent.run_async(ctx):
                yield event
            
            # Step 3: Check processing results
            audio_result = ctx.session.state.get("last_audio_generation", {})
            
            if audio_result.get("status") == "success":
                success_message = f"Audio processing completed! Audio ID: {audio_result.get('audio_id', 'unknown')}"
                ctx.session.state["audio_processing_status"] = "completed"
                
                yield Event(
                    id="audio_success",
                    type="success",
                    content=success_message,
                    author=self.name,
                    final_response=True
                )
            else:
                error_message = f"Audio processing failed: {audio_result.get('error', 'Unknown error')}"
                ctx.session.state["audio_processing_status"] = "failed"
                
                yield Event(
                    id="audio_error",
                    type="error",
                    content=error_message,
                    author=self.name
                )
                
        except Exception as e:
            error_message = f"Audio agent workflow error: {str(e)}"
            print(f"❌ [{self.name}] {error_message}")
            
            yield Event(
                id="agent_error",
                type="error",
                content=error_message,
                author=self.name
            )

    def _analyze_voice_style(self, text: str) -> str:
        """
        Analyze text content and intelligently select voice style
        
        Args:
            text: Commentary text
            
        Returns:
            Voice style (enthusiastic, dramatic, calm)
        """
        text_lower = text.lower()
        
        # Check for exciting words
        exciting_words = ['goal', 'score', 'amazing', 'incredible', 'fantastic', 'wow', 'shot', 'save']
        dramatic_words = ['overtime', 'final', 'crucial', 'critical', 'penalty', 'power play', 'empty net']
        
        if any(word in text_lower for word in dramatic_words):
            return "dramatic"
        elif any(word in text_lower for word in exciting_words):
            return "enthusiastic"
        else:
            return "enthusiastic"  # Default to enthusiastic style
    
    async def process_commentary(
        self, 
        commentary_text: str, 
        voice_style: str = "enthusiastic",
        auto_start_server: bool = True
    ) -> Dict[str, Any]:
        """
        Process commentary text and convert to audio
        
        Args:
            commentary_text: Commentary text to convert
            voice_style: Voice style (enthusiastic, dramatic, calm)
            auto_start_server: Whether to automatically start WebSocket server
            
        Returns:
            Processing result dictionary
        """
        try:
            print(f"🎙️ Processing commentary: {commentary_text[:50]}...")
            
            # Ensure WebSocket server is running
            if auto_start_server:
                server_result = await self._ensure_websocket_server()
                if server_result["status"] != "success":
                    return server_result
            
            # Generate audio
            audio_result = await self._generate_audio(commentary_text, voice_style)
            return audio_result
            
        except Exception as e:
            error_msg = f"Commentary processing failed: {str(e)}"
            print(f"❌ {error_msg}")
            return {
                "status": "error",
                "error": error_msg,
                "commentary": commentary_text[:50] + "..." if len(commentary_text) > 50 else commentary_text
            }
    
    async def _ensure_websocket_server(self) -> Dict[str, Any]:
        """
        Ensure WebSocket server is running
        
        Returns:
            Server status result
        """
        try:
            if not self.websocket_server_running:
                print("🌐 Starting WebSocket audio streaming server...")
                
                # Start server (implementation would be here)
                # For now, just mark as running
                self.websocket_server_running = True
                
                return {
                    "status": "success",
                    "message": "WebSocket server started successfully",
                    "port": 8765
                }
            else:
                return {
                    "status": "success",
                    "message": "WebSocket server already running",
                    "port": 8765
                }
                
        except Exception as e:
            error_msg = f"Failed to start WebSocket server: {str(e)}"
            print(f"❌ {error_msg}")
            return {
                "status": "error",
                "error": error_msg
            }
    
    async def _generate_audio(self, text: str, voice_style: str) -> Dict[str, Any]:
        """
        Generate audio from text
        
        Args:
            text: Text to convert
            voice_style: Voice style
            
        Returns:
            Audio generation result
        """
        try:
            # This would call the actual TTS service
            # For now, return a mock result
            audio_id = f"audio_{len(text)}_{voice_style}"
            
            return {
                "status": "success",
                "audio_id": audio_id,
                "text": text,
                "voice_style": voice_style,
                "message": f"Audio generated successfully with {voice_style} style"
            }
            
        except Exception as e:
            error_msg = f"Audio generation failed: {str(e)}"
            print(f"❌ {error_msg}")
            return {
                "status": "error",
                "error": error_msg,
                "text": text[:50] + "..." if len(text) > 50 else text
            }
    
    async def _get_current_status(self) -> Dict[str, Any]:
        """
        Get current audio agent status
        
        Returns:
            Status information dictionary
        """
        return {
            "agent_name": self.name,
            "model": self.model,
            "websocket_server_running": self.websocket_server_running,
            "status": "active"
        }
    
    async def start_audio_service(self, port: int = 8765) -> Dict[str, Any]:
        """
        Start audio streaming service
        
        Args:
            port: WebSocket server port
            
        Returns:
            Service startup result
        """
        try:
            if self.websocket_server_running:
                return {
                    "status": "info",
                    "message": f"Audio service already running on port {port}",
                    "port": port
                }
            
            # Start WebSocket server (implementation would be here)
            self.websocket_server_running = True
            
            print(f"🎵 Audio streaming service started on port {port}")
            
            return {
                "status": "success", 
                "message": f"Audio streaming service started successfully on port {port}",
                "port": port,
                "agent": self.name
            }
            
        except Exception as e:
            error_msg = f"Failed to start audio service: {str(e)}"
            print(f"❌ {error_msg}")
            return {
                "status": "error",
                "error": error_msg,
                "port": port
            }
    
    async def stop_audio_service(self) -> Dict[str, Any]:
        """
        Stop audio streaming service
        
        Returns:
            Service stop result
        """
        try:
            if not self.websocket_server_running:
                return {
                    "status": "info",
                    "message": "Audio service is not running"
                }
            
            # Stop WebSocket server (implementation would be here)
            self.websocket_server_running = False
            
            print("🛑 Audio streaming service stopped")
            
            return {
                "status": "success",
                "message": "Audio streaming service stopped successfully",
                "agent": self.name
            }
            
        except Exception as e:
            error_msg = f"Failed to stop audio service: {str(e)}"
            print(f"❌ {error_msg}")
            return {
                "status": "error",
                "error": error_msg
            }
    
    def get_agent(self) -> LlmAgent:
        """
        Get the internal LLM agent
        
        Returns:
            LLM agent instance
        """
        return self._llm_agent

# Utility functions for external use
async def process_commentary_text(text: str, style: str = "enthusiastic") -> Dict[str, Any]:
    """Process commentary text with specified style"""
    # Implementation would be here
    pass

async def start_audio_streaming_service(port: int = 8765) -> Dict[str, Any]:
    """Start audio streaming service on specified port"""
    # Implementation would be here
    pass